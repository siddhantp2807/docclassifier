{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "27/27 [==============================] - 3s 87ms/step - loss: 1.5971 - accuracy: 0.2442 - val_loss: 1.4925 - val_accuracy: 0.3426\n",
      "Epoch 2/20\n",
      "27/27 [==============================] - 2s 83ms/step - loss: 1.1886 - accuracy: 0.4884 - val_loss: 0.9581 - val_accuracy: 0.8241\n",
      "Epoch 3/20\n",
      "27/27 [==============================] - 2s 85ms/step - loss: 0.6988 - accuracy: 0.7465 - val_loss: 0.5646 - val_accuracy: 0.8935\n",
      "Epoch 4/20\n",
      "27/27 [==============================] - 2s 85ms/step - loss: 0.5199 - accuracy: 0.8021 - val_loss: 0.5586 - val_accuracy: 0.8935\n",
      "Epoch 5/20\n",
      "27/27 [==============================] - 2s 82ms/step - loss: 0.4231 - accuracy: 0.8472 - val_loss: 0.5794 - val_accuracy: 0.8704\n",
      "Epoch 6/20\n",
      "27/27 [==============================] - 2s 83ms/step - loss: 0.3772 - accuracy: 0.8600 - val_loss: 0.5456 - val_accuracy: 0.8935\n",
      "Epoch 1/20\n",
      "27/27 [==============================] - 2s 87ms/step - loss: 0.3738 - accuracy: 0.8553 - val_loss: 0.5278 - val_accuracy: 0.8565\n",
      "Epoch 2/20\n",
      "27/27 [==============================] - 2s 83ms/step - loss: 0.3633 - accuracy: 0.8657 - val_loss: 0.4991 - val_accuracy: 0.8889\n",
      "Epoch 3/20\n",
      "27/27 [==============================] - 2s 82ms/step - loss: 0.3487 - accuracy: 0.8750 - val_loss: 0.5910 - val_accuracy: 0.8704\n",
      "Epoch 4/20\n",
      "27/27 [==============================] - 2s 83ms/step - loss: 0.2668 - accuracy: 0.8819 - val_loss: 0.4711 - val_accuracy: 0.9120\n",
      "Epoch 5/20\n",
      "27/27 [==============================] - 2s 83ms/step - loss: 0.3623 - accuracy: 0.8924 - val_loss: 0.6263 - val_accuracy: 0.8935\n",
      "Epoch 6/20\n",
      "27/27 [==============================] - 2s 83ms/step - loss: 0.3003 - accuracy: 0.8935 - val_loss: 0.4977 - val_accuracy: 0.8981\n",
      "Epoch 7/20\n",
      "27/27 [==============================] - 2s 84ms/step - loss: 0.1711 - accuracy: 0.9248 - val_loss: 0.4850 - val_accuracy: 0.9120\n",
      "Evaluating the model: \n",
      "\n",
      "\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.7469 - accuracy: 0.8750\n",
      "Test accuracy: 0.875\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# load stopwords from the nltk library\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "# load data\n",
    "df = pd.read_csv('train.csv')\n",
    "\n",
    "articles = df['text']\n",
    "labels = df['label']\n",
    "\n",
    "# remove stopwords using above loaded stopwords\n",
    "for article in articles :\n",
    "    for word in STOPWORDS :\n",
    "        token = ' ' + word + ' '\n",
    "        article = article.replace(token, ' ')\n",
    "        article = article.replace(' ', ' ')\n",
    "\n",
    "# split into train and test sets\n",
    "train_df, test_df = df[:int(0.9*len(df))], df[int(0.9*len(df)):]\n",
    "\n",
    "# tokenize text\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(train_df['text'])\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "# pad sequences\n",
    "train_sequences = tokenizer.texts_to_sequences(train_df['text'])\n",
    "train_padded = pad_sequences(train_sequences, maxlen=840, padding='post', truncating='post')\n",
    "test_sequences = tokenizer.texts_to_sequences(test_df['text'])\n",
    "test_padded = pad_sequences(test_sequences, maxlen=840, padding='post', truncating='post')\n",
    "\n",
    "# convert labels to one-hot encoding\n",
    "train_labels = pd.get_dummies(train_df['label']).values\n",
    "test_labels = pd.get_dummies(test_df['label']).values\n",
    "\n",
    "# build CNN model\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(word_index) + 1, 100, input_length=840))\n",
    "model.add(Conv1D(filters=96, kernel_size=5, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(84, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(84, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "# early stopping callback to prevent overfitting\n",
    "earlystop_callback = EarlyStopping(monitor='val_accuracy', patience=3)\n",
    "\n",
    "# optimizer function\n",
    "adam = Adam(learning_rate=0.0075, beta_1=0.9175, beta_2=0.999, epsilon=3.75e-07)\n",
    "\n",
    "# compile model\n",
    "model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# create checkpoint for best accuracy weights\n",
    "checkpoint = ModelCheckpoint('best_model.h5', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "# train model\n",
    "h1 = model.fit(train_padded, train_labels, epochs=20, batch_size=32, validation_split=0.2, callbacks=[earlystop_callback, checkpoint])\n",
    "h2 = model.fit(train_padded, train_labels, epochs=20, batch_size=32, validation_split=0.2, callbacks=[earlystop_callback, checkpoint])\n",
    "# evaluate model on test set\n",
    "print(\"Evaluating the model: \\n\\n\")\n",
    "test_loss, test_acc = model.evaluate(test_padded, test_labels, verbose=1)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 26ms/step - loss: 0.6384 - accuracy: 0.9083\n",
      "Test Accuracy: 0.9083333611488342\n"
     ]
    }
   ],
   "source": [
    "# load best accuracy weights\n",
    "model.load_weights('best_model.h5')\n",
    "\n",
    "# evaluate test loss and accuracy\n",
    "test_loss, test_acc = model.evaluate(test_padded, test_labels, verbose=1)\n",
    "print('Test Accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 21ms/step\n"
     ]
    }
   ],
   "source": [
    "# create a dictionary to map integer labels to string labels\n",
    "label_map = { num: dpt for num, dpt in enumerate(list(set(labels)))}\n",
    " \n",
    "# load test set\n",
    "test_df = pd.read_csv('test.csv')\n",
    "\n",
    "# tokenize and pad test data\n",
    "test_sequences = tokenizer.texts_to_sequences(test_df['text'])\n",
    "test_padded = pad_sequences(test_sequences, maxlen=840, padding='post', truncating='post')\n",
    "\n",
    "# make predictions on test set\n",
    "predictions = model.predict(test_padded)\n",
    "predicted_labels = [label_map[np.argmax(pred)] for pred in predictions]\n",
    "\n",
    "# create submission dataframe\n",
    "submission_df = pd.DataFrame({'index': test_df['index'], 'label': predicted_labels})\n",
    "\n",
    "# save submission dataframe to CSV file\n",
    "submission_df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bayes",
   "language": "python",
   "name": "bayes"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
